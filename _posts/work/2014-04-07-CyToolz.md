---
layout: post
title: CyToolz
tagline: Functional Python, now in C
category : work
draft: true
tags : [SciPy, scipy, Python, Programming]
---
{% include JB/setup %}

**tl;dr: Our intuition that Python is slow is often incorrect.
We reimplement PyToolz, a functional standard library, in Cython.
It's fast.**

**This post highlights work done by [Erik N. Welch](http://github.com/eriknw/).
When I say "we" below, I really mean "Erik"**

PyToolz provides a suite of convenient utility functions for data processing
commonly found in functional languages.

~~~~~~~~~~Python
>>> from toolz import groupby

>>> names = ['Alice', 'Bob', 'Charlie', 'Dan', 'Edith', 'Frank']
>>> groupby(len, names)
{3: ['Bob', 'Dan'],
 5: ['Alice', 'Edith', 'Frank'],
 7: ['Charlie']}
~~~~~~~~~~

Despite being written in Pure Python and using only core data
structures, `toolz` is surprisingly fast.  In my experience `toolz` is often
fast enough even for large streaming data projects.


## We think that Python is slow

Our intuition says that Python is slow:

~~~~~~~~~~Python
>>> import numpy as np
>>> L = range(1000000)
>>> timeit sum(L)
timeit np.s100 loops, best of 3: 7.79 ms per loop

>>> A = np.arange(1000000)
>>> timeit np.sum(A)
1000 loops, best of 3: 725 µs per loop
~~~~~~~~~~

Generally speaking anything involving loops and lots of small Python operations
is much slower than the equivalent C or Java code.


## But that only applies to normally cheap operations

This slowdown is especially true of small arithmetic operations which incur a
high overhead.  However, for more complex operations, like data structure
access, this overhead is negligible.  Consider the relative difference between
integer addition and dictionary assignment.

~~~~~~~~~~Python
>>> x, y = 3, 3
>>> timeit x + y
10000000 loops, best of 3: 43.7 ns per loop

>>> d = {1: 1, 2: 2}
>>> timeit d[x] = y
10000000 loops, best of 3: 65.7 ns per loop
~~~~~~~~~~

*A Python dictionary assignment is about as fast as a Python add.*

*Disclaimer: this benchmark gets a point across but is is very artificial,
micro-benchmarks like this are hard to do well.*


## Micro-Benchmark: Frequency Counting

*Warning: cherry-picked example*

Lets count frequencies of strings.  I.e. given a long list of repeated strings

~~~~~~~~~~Python
>>> data = ['Alice', 'Bob', 'Charlie', 'Dan', 'Edith', 'Frank'] * 1000
~~~~~~~~~~

We want to count the occurence of each name.  In principle we would write a
little function like `frequencies`

~~~~~~~~~~~~Python
def frequencies(seq):
    """ Count the number of occurences of each element in seq """
    d = dict()
    for item in seq:
        if item not in d:
            d[item] = 1
        else:
            d[item] = d[item] + 1
    return d

>>> frequencies(data)
{'Alice': 1000,
 'Bob': 1000,
 'Charlie': 1000,
 'Dan': 1000,
 'Edith': 1000,
 'Frank': 1000}
~~~~~~~~~~~~~

This fairly simply operation tests grouping reductions on non-numerical data.
This represents an emerging class of algorithms that doesn't fit into our
numerical intuition on performance.

We compare the following implementations

*   Our naive Python implementation of `frequencies`
*   A naive implementation in Java, found [here](https://gist.github.com/mrocklin/3a774401288a5aad12c6)
*   The standard library's `collections.Counter`
*   PyToolz' benchmarked and tuned `frequencies` operation
*   Pandas' `Series.value_counts` method


~~~~~~~~~~
$ java Frequencies                          15   ms
~~~~~~~~~~

~~~~~~~~~~Python
>>> timeit collections.Counter(data)        1.59 ms
>>> timeit frequencies(data)                 792 µs
>>> series = Series(data)
>>> timeit series.value_counts()             722 µs
>>> timeit toolz.frequencies(data)           518 µs
~~~~~~~~~~

We make the following observations:

*   The standard library solution `Counter` surprisingly performs the
    worst.  This is a bit unfair as the `Counter` object is a bit more complex,
    providing slightly more exotic functionality that we don't use here.
*   The Pandas solution, which uses C code and C data structures isn't that much
    better than the naive Python solution.
*   The `toolz.frequencies` function, which is pure Python and uses Python
    data stuctures performs the best here.  The PyToolz development team
    has benchmarked and tuned several implementatations.  I believe that this is
    the [fastest solution  available](http://toolz.readthedocs.org/en/latest/_modules/toolz/itertoolz.html#frequencies)
    in Pure Python.

Lets also note that all of the Python solutions are *very fast* relative to the
Java solution.  *For data structure bound computations, Python is fast.*


CyToolz
-------

Personally, I'm fine with fast Python speeds.  Erik on the other hand,
wanted unreasonable C speeds so he rewrote `toolz` in Cython;  he calls it
`cytoolz`.  His results are pretty amazing.

~~~~~~~~~~Python
>>> # import toolz
>>> import cytoolz

>>> timeit series.value_counts()             722 µs
>>> timeit toolz.frequencies(data)           518 µs
>>> timeit cytoolz.frequencies(data)         203 µs
~~~~~~~~~~

Lets appreciate this for a moment.

Pandas uses both C-backed code and data structures (Cython, NumPy) while cytoolz
uses C-backed code (Cython) but Python-backed data structures (lists, dicts,
...)  It's startling to see how well cytoolz does with native Python types.

| Project          | Computation      |   Data Structures        |
|:-----------------|:-----------------|:-------------------------|
| PyToolz          | Python           | Python (list, dict, ...) |
| Pandas/NumPy     | C / Cython       | C / NumPy NDArray        |
| CyToolz          | C / Cython       | Python (list, dict, ...) |


A note on Functional Programming
--------------------------------

PyToolz integrates functional principles into traditional Python programming.
CyToolz supports these same functional principles, in the same workflow, but
now backed by C speeds

I started PyToolz because I liked Clojure's standard library but couldn't stay
on the JVM (I needed native code interaction).  Originally I thought of Python
and PyToolz as being a hack providing functional programming abstractions in an
imperative language.  I've now come to think of Python as being a very
performant and serious functional language in its own right.  While it lacks macros,
monads, and any sort of type system, it's amazing for 99% of the pedestrian
programming that I do day to day.


Conclusion
----------

The `toolz` functions are simple, fast, and a great way to compose clear and
performant code.  Check out [the docs](http://toolz.readthedocs.org/) and find
a function that you didn't know you needed, or a function that you needed,
wrote, but didn't benchmark quite as heavily as we did.

If you're already a savvy `toolz` user and want Cython speed then you'll be
happy to know that the cytoolz library is a drop in replacement.

    $ pip install cytoolz

~~~~~~~~~~Python
# from toolz import *
from cytoolz import *
~~~~~~~~~~

Most functions improve by 2x-5x with some fantastic exceptions.
