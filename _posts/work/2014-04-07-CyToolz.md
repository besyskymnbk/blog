---
layout: post
title: CyToolz
tagline: Functional Python, now in C
category : work
draft : true
tags : [SciPy, scipy, Python, Programming]
---
{% include JB/setup %}

**tl;dr: We reimplement PyToolz, a functional standard library, in Cython.
It's fast.**

**This post highlights work done by [Erik N. Welch](http://github.com/eriknw/).
When I say "we" below, I really mean "Erik"**

PyToolz provides a suite of convenient utility functions for data processing
commonly found in functional languages.

~~~~~~~~~~Python
>>> from toolz import groupby

>>> names = ['Alice', 'Bob', 'Charlie', 'Dan', 'Edith', 'Frank']
>>> groupby(len, names)
{3: ['Bob', 'Dan'],
 5: ['Alice', 'Edith', 'Frank'],
 7: ['Charlie']}
~~~~~~~~~~

Despite being written in Pure Python (2 and 3) and using only core data
structures, `toolz` is surprisingly fast.  In my experience `toolz` is often
fast enough even for large streaming data projects.

Lets compare it to Pandas (warning: cherry-picked example)

~~~~~~~~~~Python
>>> # 100000 random integers between 0 and 10
>>> data = [random.randint(0, 10) for i in range(100000)]
>>> data[:5]
[2, 3, 9, 3, 10]

>>> frequencies(data)
{0: 9223,
 1: 9091,
 2: 9102,
 3: 9053,
 4: 9110,
 5: 9150,
 6: 8993,
 7: 9162,
 8: 9080,
 9: 9056,
 10: 8980}

>>> from pandas import DataFrame
>>> df = DataFrame(data, columns=['numbers'])
>>> df.groupby('numbers').size()
numbers
0          9223
1          9091
2          9102
3          9053
4          9110
5          9150
6          8993
7          9162
8          9080
9          9056
10         8980
dtype: int64
~~~~~~~~~~

Good, same result.  How fast are they?

~~~~~~~~~~Python
>>> timeit frequencies(data)
100 loops, best of 3: 8.31 ms per loop

>>> timeit df.groupby('numbers').size()
100 loops, best of 3: 3.92 ms per loop
~~~~~~~~~~

Sure, pandas wins, but only by a factor of two-ish.  *Python is reasonably
fast*, particularly when computations are data structure bound (See [related
blogpost](http://matthewrocklin.com/blog/work/2014/01/13/Text-Benchmarks/))


CyToolz
-------

Personally, I'm fine with reasonable Python speeds.  Erik on the other hand,
wanted unreasonable C speeds so he rewrote `toolz` in Cython;  he calls it
`cytoolz`.  His results are pretty amazing.

~~~~~~~~~~Python
>>> import toolz
>>> import cytoolz

>>> timeit toolz.frequencies(data)
100 loops, best of 3: 8.31 ms per loop

>>> timeit cytoolz.frequencies(data)
100 loops, best of 3: 3.51 ms per loop
~~~~~~~~~~

And just for comparison lets see the Pandas numbers again

~~~~~~~~~~Python
>>> timeit df.groupby('numbers').size()
100 loops, best of 3: 3.92 ms per loop
~~~~~~~~~~

On this operation `cytoolz` is actually *faster than pandas* despite using only
core Python data structures (again, disclaimer, this example is cherry-picked).

Lets appreciate this for a moment.

Pandas uses both C-backed code and data structures (Cython, NumPy) while cytoolz
uses C-backed code (Cython) but Python-backed data structures (lists, dicts,
...)  It's startling to see how well cytoolz does with native Python types.

PyToolz integrates functional principles into traditional Python programming.
CyToolz supports these same functional principles, in the same workflow, but
now backed by C speeds

Conclusion
----------

The `toolz` functions are simple, fast, and a great way to compose clear and
performant code.  Check out [the docs](http://toolz.readthedocs.org/) and find
a function that you didn't know you needed, or a function that you needed,
wrote, but didn't benchmark quite as heavily as we did.

If you're already a savvy `toolz` user and want Cython speed then you'll be
happy to know that the cytoolz library is a drop in replacement.

    $ pip install cytoolz

~~~~~~~~~~Python
# from toolz import *
from cytoolz import *
~~~~~~~~~~

Most functions improve by 2x-5x with some fantastic exceptions.
