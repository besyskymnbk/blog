---
layout: post
title: Dask-GLM development
draft: true
category: work
tags: [Programming, Python, scipy]
theme: twitter
---
{% include JB/setup %}

*This work is supported by [Continuum Analytics](http://continuum.io)
the [XDATA Program](http://www.darpa.mil/program/XDATA)
and the Data Driven Discovery Initiative from the [Moore
Foundation](https://www.moore.org/).*

Summary
-------

We discuss building distributed optimization algorithms with Dask.  We show
both some simple examples and benchmarks.  We also talk about the experience of
learning Dask to do this kind of work.

This blogpost is co-authored by Chris White (Capital One) who knows
optimization and Matthew Rocklin (Continuum Analytics) who knows distributed
computing.


Introduction
------------

Many machine learning and statistics algorithms like logistic regression depend
on convex optimization algorithms like Newton's method, stochastic gradient
descent, and others.  These optimization algorithms are both pragmatic (they're
used in many applications) and mathematically interesting.  As a result these
algorithms have been the subject of study by researchers and graduate students
around the world for years both in academia and in industry.

Things got interesting about five or ten years ago when datasets grew beyond
the size of working memory and "Big Data" became a buzzword.  Now parallel and
distributed solutions for these algorithms have become the norm, and a
researcher's skillset now has to extend beyond linear algebra and optimization
theory to include parallel algorithms and possibly even network programming,
especially if you want to explore and create more interesting algorithms.

1.  Algorithmic researcher (Chris): someone who knows optimization and
    iterative algorithms like ***,  (TODO: Chris fill in) but isn't so hot on
    distributed computing topics like sockets, MPI, load balancing, etc..
2.  Distributed systems/Dask developer (Matt): someone who knows how to move
    bytes around and keep machines busy but doesn't know the right way to do a
    line search or handle a poorly conditioned matrix


Examples
--------

TODO: Chris


Experiment
----------

*We compare dask-glm implementations against Scikit-learn on a laptop, and then
show them running on a cluster.*

*Reproducible notebook is available here: TODO*

We've already done the work above, and more, in the nascent [dask-glm
project](https://github.com/dask/dask-glm).  This project has convex
optimization algorithms for gradient descent, proximal gradient descent,
newton's method, and ADMM.  These implementations extend the implementations
above by also thinking about stopping criteria and other niceties that we
avoided above for simplicity.

how off these algorithms we're going to perform a simple numerical experiment
that compares the numerical performance of proximal gradient descent and ADMM
alongside Scikit-Learn's LogisiticRegression and SGD implementations on a
single machine (a personal laptop) and then follows up by scaling the dask-glm
options to a moderate cluster.  As a disclaimer, these experiments will be
somewhat crude.  We're using artificial data, we're not tuning parameters or
even finding parameters at which these algorithms are producing results of the
same accuracy.  The goal of this section is just to give a general feeling of
how things compare.

We create data

```python
## size of problem (no. observations)
N = 8e6
chunks = 1e6
seed = 20009
beta = (np.random.random(15) - 0.5) * 3

X = da.random.random((N,len(beta)), chunks=chunks)
y = make_y(X, beta=np.array(beta), chunks=chunks)

X, y = persist(X, y)
client.rebalance([X, y])
```

And run each of our algorithms as follows:

```python
# Dask-GLM Proximal Gradient
proximal_grad(X, y, lamduh=alpha)

# Dask-GLM ADMM
X2 = X.rechunk((1e5, None)).persist()  # ADMM prefers smaller chunks
y2 = y.rechunk(1e5).persist()
result = admm(X2, y2, lamduh=alpha)

# Scikit-Learn LogisticRegression
nX, ny = compute(X, y)  # sklearn wants numpy arrays
LogisticRegression(penalty='l1', C=1).fit(nX, ny).coef_

# Scikit-Learn Stochastic Gradient Descent
SGDClassifier(loss='log',
              penalty='l1',
              l1_ratio=1,
              n_iter=10,
              fit_intercept=False).fit(nX, ny).coef_
```

We then compare with the $L_{\infty}$ norm (largest different value).

```python
abs(result - beta).max()
```

Times and accuracies for these parameters are shown in the table below:

<table>
<thead><tr>
  <th>Algorithm</th>
  <th>Error</th>
  <th>Duration (s)</th>
</tr></thead>
<tbody>
<tr>
  <td>Proximal Gradient</td>
  <td>0.0227</td>
  <td>128</td>
</tr>
<tr>
  <td>ADMM</td>
  <td>0.0125</td>
  <td>34.7</td>
</tr>
<tr>
  <td>LogisticRegression</td>
  <td>0.0132</td>
  <td>79</td>
</tr>
<tr>
  <td>SGDClassifier</td>
  <td>0.0456</td>
  <td>29.4</td>
</tr>
</tbody>
<table>

Again, please don't take these numbers too seriously.  TODO: Chris add
disclaimers.  Also, Dask-glm is using a full four-core laptop while SKLearn is
restricted to use a single core.


TODO Matt: Add profile plots

The general takeaway here is that dask-glm does comparably on a single machine.
If your problem fits nicely on a single machine you should continue to use
Scikit-Learn and Statsmodels.  The real benefit here is that the Dask-GLM
algorithms *scale*.  They can run efficiently on data that is
larger-than-memory by operating off of disk and they can run efficiently on a
cluster.

### Cluster Computing

As a demonstration, we run a larger version of the data above on a cluster of
eight machines on EC2.  We find that performance scales as expected.

TODO Matt: Run experiment, include profile plots.


### Analysis

The algorithms in Dask-GLM are new and need development, but are in a usable
state by people comfortable operating at this technical level.  Additionally,
we would like to attract other mathematical and algorithmic developers to this
work.  We've found that Dask provides a nice balance between being flexible
enough to support interesting algorithms, while being managed enough to be
usable by researchers without a strong background in distributed systems.  In
this section we're going to discuss the things that we learned (from both
Chris' (mathematical algorithms) and Matt's (distributed systems) perspective
and then talk about possible future work.  We encourage people to pay attention
to future work; we're open to collaboration and think that this is a good
opportunity for new researchers to meaningfully engage.

#### Chris's perspective

TODO: Chris

#### Matt's perspective

This work triggered a number of concrete changes within the Dask library:

1.  We can convert Dask.dataframes to Dask.arrays.  This is particularly
    important because people want to do pre-processing with dataframes but then
    switch to efficient multi-dimensional arrays for algorithms.
2.  We had to unify the single-machine scheduler and distributed scheduler APIs
    a bit, notably adding a `persist` function to the single machine
    scheduler.  This was particularly important because Chris
    generally prototyped on his laptop but we wanted to write code that was
    effective on clusters.
3.  Scheduler overhead can be a problem for the iterative dask-array algorithms
    (gradient descent, proximal gradient descent, BFGS).  This is particulalry
    a problem because NumPy is very fast.  Often our tasks take only a few
    milliseconds, which makes Dask's overhead of 200us per task become very
    relevant.  We've started resolving this problem in a few ways like more
    aggressive task fusion and lower overheads generally.  In practice we've
    started handling this just by choosing chunksizes well.  I suspect that for
    the dask-glm in particular we'll just develop auto-chunksize heuristics.
    We expect this problem to recur in other work with scientists on HPC
    systems who have similar problems.
4.  A couple of things can be tricky for algorithmic users:
    1.  Placing the calls to asynchronously start computation (persist, compute)
        In practice Chris did a good job here and then I came through and
        tweaked things afterwards.  The web diagnostics ended up being crucial
        to identify issues here.
    2.  Avoiding accidentally calling NumPy functions on dask.arrays and vice
        versa.  We've improved this on the dask.array side, they now operate
        intelligently when given numpy arrays.  Changing this on the NumPy side
        is harder until NumPy protocols change (which is planned).


#### Future work

There are a number of things we would like to do, both in terms of measurement
and for the dask-glm project itself.  We welcome people to voice their opinions
(and join development) on the following issues:

1.  Asynchronous Algorithms  ... TODO: link to github issues
2.  User APIs
3.  Extend GLM families
4.  ... TODO: Chris add things here
